{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/work/Desktop/Learn2SelectNodes/Learn2SelectNodes/LP/instances1/merged.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_0</th>\n",
       "      <th>features_1</th>\n",
       "      <th>features_2</th>\n",
       "      <th>features_3</th>\n",
       "      <th>features_4</th>\n",
       "      <th>features_5</th>\n",
       "      <th>features_6</th>\n",
       "      <th>features_7</th>\n",
       "      <th>features_8</th>\n",
       "      <th>features_9</th>\n",
       "      <th>features_10</th>\n",
       "      <th>features_11</th>\n",
       "      <th>features_12</th>\n",
       "      <th>features_13</th>\n",
       "      <th>features_14</th>\n",
       "      <th>features_15</th>\n",
       "      <th>features_16</th>\n",
       "      <th>features_17</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6842550312313129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008928571428571428</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.9123715746189686</td>\n",
       "      <td>-0.31574496876868713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12446575756920362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25233676563610546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6832333572802517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0017857142857142857</td>\n",
       "      <td>-0.9967746794855383</td>\n",
       "      <td>-0.40458949609296063</td>\n",
       "      <td>-0.31574496876868713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06833752815141685</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.18686261314400726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6832333572802517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0026785714285714286</td>\n",
       "      <td>-0.9967746794855383</td>\n",
       "      <td>-0.5961116451376592</td>\n",
       "      <td>-0.31574496876868713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.6764614086241016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13520408163265304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6832333572802517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0017857142857142857</td>\n",
       "      <td>-0.9967746794855383</td>\n",
       "      <td>-0.5393274578962987</td>\n",
       "      <td>-0.31574496876868713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06923132439701013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6764614086241016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6832333572802517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0026785714285714286</td>\n",
       "      <td>-0.9967746794855383</td>\n",
       "      <td>-0.6271681931120865</td>\n",
       "      <td>-0.31574496876868713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09539440763729409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.863048581690451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19196428571428573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features_0 features_1             features_2           features_3  \\\n",
       "0  0.6842550312313129          0  0.0008928571428571428                 -1.0   \n",
       "1  0.6832333572802517          0  0.0017857142857142857  -0.9967746794855383   \n",
       "2  0.6832333572802517          0  0.0026785714285714286  -0.9967746794855383   \n",
       "3  0.6832333572802517          0  0.0017857142857142857  -0.9967746794855383   \n",
       "4  0.6832333572802517          0  0.0026785714285714286  -0.9967746794855383   \n",
       "\n",
       "             features_4            features_5 features_6           features_7  \\\n",
       "0   -0.9123715746189686  -0.31574496876868713          0  0.12446575756920362   \n",
       "1  -0.40458949609296063  -0.31574496876868713          0  0.06833752815141685   \n",
       "2   -0.5961116451376592  -0.31574496876868713          0                  0.0   \n",
       "3   -0.5393274578962987  -0.31574496876868713          0  0.06923132439701013   \n",
       "4   -0.6271681931120865  -0.31574496876868713          0  0.09539440763729409   \n",
       "\n",
       "  features_8 features_9 features_10 features_11 features_12  \\\n",
       "0          0          1           0           0         1.0   \n",
       "1          0          1           0           0         1.0   \n",
       "2          1          1           0           0        -1.0   \n",
       "3          0          0           1           0         0.0   \n",
       "4          1          0           1           0        -1.0   \n",
       "\n",
       "           features_13 features_14 features_15 features_16  \\\n",
       "0  0.25233676563610546           0           0           0   \n",
       "1  0.18686261314400726           0           0           0   \n",
       "2  -0.6764614086241016           0           0           0   \n",
       "3  -0.6764614086241016           0           0           0   \n",
       "4   -0.863048581690451           0           0           0   \n",
       "\n",
       "           features_17 label  \n",
       "0                  0.0     0  \n",
       "1                  0.0     1  \n",
       "2  0.13520408163265304     1  \n",
       "3                  0.0     1  \n",
       "4  0.19196428571428573     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # self.nodeselGap = 0 \n",
    "#         self.nodeselGapInf = 0 \n",
    "#         self.relativeDepth = 0\n",
    "#         self.lowerBound = 0 \n",
    "#         self.estimate = 0\n",
    "#         self.relativeBound = 0\n",
    "#         self.globalUpperBound = 0\n",
    "#         self.globalUpperBoundInf = 0\n",
    "#         self.plungeDepth = 0  \n",
    "#         self.nodeIsSibling = 0 \n",
    "#         self.nodeIsChild = 0 \n",
    "#         self.nodeIsLeaf = 0 \n",
    "#         '''\n",
    "#         These features below are the features obtained according to the branching \n",
    "#         status at the time of a particular node being focussed. \n",
    "#         '''\n",
    "#         # self.branchFeatures = []\n",
    "#         self.boundLPDiff = 0 \n",
    "#         self.rootLPDiff = 0\n",
    "#         self.pseudocost = 0 \n",
    "#         self.branchPriorityDown = 0\n",
    "#         self.branchPriorityUp = 0\n",
    "#         self.branchVarInf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataset:\n",
    "    dataset[column] = pd.to_numeric(dataset[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = dataset.boxplot(column=['features_8'], by=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_0</th>\n",
       "      <th>features_1</th>\n",
       "      <th>features_2</th>\n",
       "      <th>features_3</th>\n",
       "      <th>features_4</th>\n",
       "      <th>features_5</th>\n",
       "      <th>features_6</th>\n",
       "      <th>features_7</th>\n",
       "      <th>features_8</th>\n",
       "      <th>features_9</th>\n",
       "      <th>features_10</th>\n",
       "      <th>features_11</th>\n",
       "      <th>features_12</th>\n",
       "      <th>features_13</th>\n",
       "      <th>features_14</th>\n",
       "      <th>features_15</th>\n",
       "      <th>features_16</th>\n",
       "      <th>features_17</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.0</td>\n",
       "      <td>602102.000000</td>\n",
       "      <td>602102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.201093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>-0.766321</td>\n",
       "      <td>-0.420312</td>\n",
       "      <td>-0.609128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689786</td>\n",
       "      <td>2.428368</td>\n",
       "      <td>0.495481</td>\n",
       "      <td>0.504519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.450824</td>\n",
       "      <td>-0.777014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>0.828194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.060861</td>\n",
       "      <td>0.067747</td>\n",
       "      <td>0.026628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254224</td>\n",
       "      <td>1.845927</td>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588111</td>\n",
       "      <td>0.226672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.377212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.698699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.159638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>-0.798559</td>\n",
       "      <td>-0.460739</td>\n",
       "      <td>-0.628629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.859067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.192612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>-0.756845</td>\n",
       "      <td>-0.415420</td>\n",
       "      <td>-0.605221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.825710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105698</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.232168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>-0.722442</td>\n",
       "      <td>-0.374450</td>\n",
       "      <td>-0.593148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.786492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138133</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.776884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>-0.642963</td>\n",
       "      <td>-0.171331</td>\n",
       "      <td>-0.223116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998962</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.059609</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          features_0  features_1     features_2     features_3     features_4  \\\n",
       "count  602102.000000    602102.0  602102.000000  602102.000000  602102.000000   \n",
       "mean        0.201093         0.0       0.020502      -0.766321      -0.420312   \n",
       "std         0.059067         0.0       0.008568       0.060861       0.067747   \n",
       "min         0.067029         0.0       0.000671      -1.000000      -1.000000   \n",
       "25%         0.159638         0.0       0.014286      -0.798559      -0.460739   \n",
       "50%         0.192612         0.0       0.019403      -0.756845      -0.415420   \n",
       "75%         0.232168         0.0       0.025424      -0.722442      -0.374450   \n",
       "max         0.776884         0.0       0.066400      -0.642963      -0.171331   \n",
       "\n",
       "          features_5  features_6     features_7     features_8     features_9  \\\n",
       "count  602102.000000    602102.0  602102.000000  602102.000000  602102.000000   \n",
       "mean       -0.609128         0.0       0.689786       2.428368       0.495481   \n",
       "std         0.026628         0.0       0.254224       1.845927       0.499980   \n",
       "min        -0.698699         0.0       0.000000       0.000000       0.000000   \n",
       "25%        -0.628629         0.0       0.536208       1.000000       0.000000   \n",
       "50%        -0.605221         0.0       0.763423       2.000000       0.000000   \n",
       "75%        -0.593148         0.0       0.899988       4.000000       1.000000   \n",
       "max        -0.223116         0.0       0.998962      35.000000       1.000000   \n",
       "\n",
       "         features_10  features_11    features_12    features_13  features_14  \\\n",
       "count  602102.000000     602102.0  602102.000000  602102.000000     602102.0   \n",
       "mean        0.504519          0.0      -0.450824      -0.777014          0.0   \n",
       "std         0.499980          0.0       0.588111       0.226672          0.0   \n",
       "min         0.000000          0.0      -1.000000      -1.000000          0.0   \n",
       "25%         0.000000          0.0      -1.000000      -0.859067          0.0   \n",
       "50%         1.000000          0.0       0.000000      -0.825710          0.0   \n",
       "75%         1.000000          0.0       0.000000      -0.786492          0.0   \n",
       "max         1.000000          0.0       1.000000       0.397344          0.0   \n",
       "\n",
       "       features_15  features_16    features_17          label  \n",
       "count     602102.0     602102.0  602102.000000  602102.000000  \n",
       "mean           0.0          0.0       0.099948       0.828194  \n",
       "std            0.0          0.0       0.104582       0.377212  \n",
       "min            0.0          0.0       0.000000       0.000000  \n",
       "25%            0.0          0.0       0.000999       1.000000  \n",
       "50%            0.0          0.0       0.105698       1.000000  \n",
       "75%            0.0          0.0       0.138133       1.000000  \n",
       "max            0.0          0.0       3.059609       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = dataset['label']\n",
    "X = dataset\n",
    "del X['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=123).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869541026897302"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=18, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "481681/481681 [==============================] - 8s 16us/step - loss: 0.2758 - acc: 0.8760\n",
      "Epoch 2/15\n",
      " 39680/481681 [=>............................] - ETA: 8s - loss: 0.2532 - acc: 0.8865"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f0627f7aec2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120421/120421 [==============================] - 2s 18us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25515588076280016, 0.8813911194891256]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train_svm = preprocessing.scale(X_train)\n",
    "X_test_svm = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# clf_svm = svm.SVC(kernel='linear')\n",
    "# clf_svm.fit(X_train, y_train)\n",
    "# clf_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8d143b9444f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "X_train = X_train.dropna()\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
