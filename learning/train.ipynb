{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1135eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from pathlib import Path\n",
    "from model import GNNPolicy\n",
    "from data_type import GraphDataset\n",
    "from utils import process\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982bad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"FCMCNF\"\n",
    "lr = 0.005\n",
    "n_epoch = 5\n",
    "patience = 10\n",
    "early_stopping = 20\n",
    "normalize = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_train = 1\n",
    "batch_valid  = 256\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer_fn = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1c3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "GNN for problem FCMCNF\n",
      "Training on:          128098 samples\n",
      "Validating on:        0 samples\n",
      "Batch Size Train:     1\n",
      "Batch Size Valid      256\n",
      "Learning rate:        0.005 \n",
      "Number of epochs:     5\n",
      "Normalize:            True\n",
      "Device:               cuda\n",
      "Loss fct:             BCELoss()\n",
      "Optimizer:            <class 'torch.optim.adam.Adam'>\n",
      "Model's Size:         1050 parameters \n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "train_files = [ str(path) for path in Path(os.path.join(os.path.abspath(''), \n",
    "                                                        f\"../node_selection/data/{problem}/train\")).glob(\"*.pt\") ]\n",
    "\n",
    "valid_files = [ str(path) for path in Path(os.path.join(os.path.abspath(''), \n",
    "                                                        f\"../node_selection/data/{problem}/valid\")).glob(\"*.pt\") ]\n",
    "\n",
    "train_data = GraphDataset(train_files)\n",
    "valid_data = GraphDataset(valid_files)\n",
    "\n",
    "#inspect(train_data[:100])\n",
    "\n",
    "# TO DO : learn something from the data\n",
    "train_loader = torch_geometric.loader.DataLoader(train_data, \n",
    "                                                 batch_size=batch_train, \n",
    "                                                 shuffle=True, \n",
    "                                                 follow_batch=['constraint_features_s', \n",
    "                                                               'constraint_features_t',\n",
    "                                                               'variable_features_s',\n",
    "                                                               'variable_features_t'])\n",
    "\n",
    "valid_loader = torch_geometric.loader.DataLoader(valid_data, \n",
    "                                                 batch_size=batch_valid, \n",
    "                                                 shuffle=False, \n",
    "                                                 follow_batch=['constraint_features_s',\n",
    "                                                               'constraint_features_t',\n",
    "                                                               'variable_features_s',\n",
    "                                                               'variable_features_t'])\n",
    "\n",
    "policy = GNNPolicy().to(device)\n",
    "optimizer = optimizer_fn(policy.parameters(), lr=lr) #ADAM is the best\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(f\"GNN for problem {problem}\")\n",
    "print(f\"Training on:          {len(train_data)} samples\")\n",
    "print(f\"Validating on:        {len(valid_data)} samples\")\n",
    "print(f\"Batch Size Train:     {batch_train}\")\n",
    "print(f\"Batch Size Valid      {batch_valid}\")\n",
    "print(f\"Learning rate:        {lr} \")\n",
    "print(f\"Number of epochs:     {n_epoch}\")\n",
    "print(f\"Normalize:            {normalize}\")\n",
    "print(f\"Device:               {device}\")\n",
    "print(f\"Loss fct:             {loss_fn}\")\n",
    "print(f\"Optimizer:            {optimizer_fn}\")  \n",
    "print(f\"Model's Size:         {sum(p.numel() for p in policy.parameters())} parameters \")\n",
    "print(\"-------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79d8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 0.087, accuracy 0.992\n",
      "Valid loss: 0.000, accuracy 0.000\n",
      "Epoch 2\n",
      "Train loss: 0.095, accuracy 0.992\n",
      "Valid loss: 0.000, accuracy 0.000\n",
      "Epoch 3\n",
      "Train loss: 0.095, accuracy 0.992\n",
      "Valid loss: 0.000, accuracy 0.000\n",
      "Epoch 4\n",
      "Train loss: 0.097, accuracy 0.992\n",
      "Valid loss: 0.000, accuracy 0.000\n",
      "Epoch 5\n",
      "Train loss: 0.092, accuracy 0.992\n",
      "Valid loss: 0.000, accuracy 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    train_loss, train_acc = process(policy, \n",
    "                                    train_loader, \n",
    "                                    loss_fn,\n",
    "                                    device,\n",
    "                                    optimizer=optimizer, \n",
    "                                    normalize=normalize)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    print(f\"Train loss: {train_loss:0.3f}, accuracy {train_acc:0.3f}\" )\n",
    "\n",
    "    valid_loss, valid_acc = process(policy, \n",
    "                                    valid_loader, \n",
    "                                    loss_fn, \n",
    "                                    device,\n",
    "                                    optimizer=None,\n",
    "                                    normalize=normalize)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "    print(f\"Valid loss: {valid_loss:0.3f}, accuracy {valid_acc:0.3f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd0910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDataset(1269)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(policy.state_dict(),f'policy_{problem}.pkl')\n",
    "res = 0\n",
    "for i in train_data:\n",
    "    res += i.y if i.y == 1 else 0\n",
    "train_data[10]\n",
    "res\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = [ policy(dvalid.to(device)).item() for dvalid in valid_data ]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0)\n",
    "plt.hist(decisions)\n",
    "plt.title('decisions histogramme for valid set')\n",
    "plt.savefig(\"./hist.png\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(valid_losses, label='valid')\n",
    "plt.title('losses')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"./losses.png\")\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(train_accs, label='train')\n",
    "plt.plot(valid_accs, label='valid')\n",
    "plt.title('accuracies')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"./accuracies.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
